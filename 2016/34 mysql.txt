

***********************************************************************

mysql

innoDB逻辑存储结构：表空间、段、区、页、行；

第1章：概述；
	mysql数据类型
		1、数值类型：TINYINT、SMALLINT、MEDIUMINT、INT或INTEGER、BIGINT、FLOAT、DOUBLE、DECIMAL(M,D);
		2、字符串：CHAR、VARCHAR、TINYBLOB、TINYTEXT、BLOB、TEXT、MEDIUMBLOB、MEDIUMTEXT、LOGNGBLOB、LONGTEXT、VARBINARY(M)、BINARY(M);
		3、日期/时间：DATE、TIME、YEAR、DATETIME、TIMESTAMP;
		4、复合类型：ENUM、SET;

第2章：InnoDB体系架构
	
	后台线程
		InnoDB存储引擎是多线程的模型，因此其后台有多个不同的后台线程；
		1、Master Thread：将缓冲池中的数据异步刷新到磁盘，保证数据的一致性；
		
		2、IO Thread：在InnoDB中大量使用了AIO来处理IO请求，IO Thread的工作主要是负责这些IO请求的回调处理；
			包含：write、read、insert buffer、log IO Thread, 
			可以使用innodb_read_io_threads、innodb_write_io_threads参数进行设置，默认是4个；
			show variables like 'innodb_version';
			show variables like 'innodb_%io_threads';//显示读写IO线程的数量
			show engine innodb status;
		
		3、Purge Thread：事务被提交后，其所使用的undolog可能不再需要，因此需要PurgeThread来回收已经使用并分配的undo页。
			show variables like 'innodb_purge_threads';
			
		4、Page Cleaner Thread：将之前脏页刷新的操作都放入到单独的线程中来完成，减轻原Master Thread的工作；
		
	内存
		1、缓冲池
			在数据库中进行读取页的操作时，首先将从磁盘读到的页存放在缓冲池中，下次再读到相同的页时，首先判断该页是否在缓冲池中；
				若在缓冲池中，直接读取该页，否则读取磁盘；
			对于数据库中页的修改操作，则首先修改在缓冲池中的页，然后以一定的频率刷新到磁盘上；需要注意的是，页从缓冲池刷新回磁盘
				的操作并不是每次页发生更新时触发，而是通过checkpoint的机制刷新回磁盘。
			
			查看缓冲池大小：show variables like 'innodb_buffer_pool_size';
			
			可以设置多个缓冲池实例，每个页根据哈希值平均分配到不同缓冲池实例中；这样做的好处是减少数据库内部的资源竞争，增加数据库
				的并发处理能力；
				show variables like 'innodb_buffer_pool_instances';
				select pool_id, pool_size, free_buffers, database_pages from innodb_buffer_pool_stats;
				
			查询midpoint值：
				show variables like 'innodb_old_blocks_pct';
		
			缓冲池中缓存的数据页类型：索引页、数据页、undo页、插入缓冲、自适应哈希索引、innoDB存储的锁信息、数据字典信息等；
		
		2、LRU List、Free List、Flush List
			LRU：最近最少使用；
				midpoint位置：新的数据先放到midpoint后面，以防止热点数据被挤出去；
					show variables like 'innodb_old_blocks_pct';
				
				页读取到mid位置后需要等待多久才会被加入到LRU列表的热端，
					show variables like 'innodb_old_blocks_time';
			
			Free List：用来存储哪些页是空闲的，可以分配给LRU List；
			Flush List：存放着脏页，即被修改了的LRU List中的数据，通过CHECKPOINT机制将脏页刷新到磁盘上；
		
		3、重做日志缓冲：Innodb首先将重做日志信息先放入到这个缓冲区，然后按一定频率将其刷新到重做日志文件；
			show variables like 'innodb_log_buffer_size';
			
			redo->每次操作都先记录到redo日志中，当出现实例故障（像断电），导致数据未能更新到数据文件，则数据库重启时须redo，重新把数据更新到数据文件;
			undo->记录更改前的一份copy，但你系统rollback时，把这份copy重新覆盖到原来的数据;
		
		4、额外的内存池：当本身的内存不够时，会向额外缓冲池申请；
		
		5、redolog
			InnoDB有buffer pool（简称bp）。bp是数据库页面的缓存，对InnoDB的任何修改操作都会首先在bp的page上进行，然后这样的页面将被标记为dirty并被放到专门的flush list上，
			后续将由master thread或专门的刷脏线程阶段性的将这些页面写入磁盘（disk or ssd）。这样的好处是避免每次写操作都操作磁盘导致大量的随机IO，
			阶段性的刷脏可以将多次对页面的修改merge成一次IO操作，同时异步写入也降低了访问的时延。然而，如果在dirty page还未刷入磁盘时，server非正常关闭，这些修改操作将会丢失，
			如果写入操作正在进行，甚至会由于损坏数据文件导致数据库不可用。为了避免上述问题的发生，Innodb将所有对页面的修改操作写入一个专门的文件，
			并在数据库启动时从此文件进行恢复操作，这个文件就是redo log file。这样的技术推迟了bp页面的刷新，从而提升了数据库的吞吐，有效的降低了访问时延。
			带来的问题是额外的写redo log操作的开销（顺序IO，当然很快），以及数据库启动时恢复操作所需的时间。
			
	CheckPoint技术
		当数据库宕机时，数据库不需要重做所有的日志，因为Checkpoint之前的页都已经刷新回磁盘了，数据库只需要对Checkpoint后的重做日志进行恢复；
		
	InnoDB新特性
		1、插入缓冲：Insert Buffer、Change Buffer；
			聚集索引表示表中存储的数据按照索引的顺序存储，检索效率比非聚集索引高，但对数据更新影响较大。
			非聚集索引表示数据存储在一个地方，索引存储在另一个地方，索引带有指针指向数据的存储位置，非聚集索引检索效率比聚集索引低，但对数据更新影响较小。
			对非聚集索引的插入和更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引是否在缓冲池中，若在，则直接插入，若不在，则先放入到
				一个Insert Buffer对象中，即缓冲池中，好似欺骗；insert buffer使用条件：1、辅助索引；2：索引不是唯一的；
			
		2、两次写：保证InnoDB数据页的可靠性；
			当数据库发生宕机时，可能InnoDB存储引擎正在写入某个页到表中，而这个页只写了一部分，比如16KB，只写了前4KB，之后就发生宕机，这种情况被称为部分写
			失效，导致数据丢失；可以根据重做日志恢复吗？重做日志中记录的是对页的物理操作，如果这个页本身已经损坏，再对其进行重做也没意义；
			在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是会通过memcpy函数将脏页先复制到内存中的doublewrite buffer，之后通过doublewrite buffer再分
				两次，每次1MB顺序地写入共享表空间的物理磁盘上，然后马上调用fsync函数，同步磁盘；
				
		3、自适应hash索引 AHI
			InnoDB会监控表上各索引页的查询，对于热点数据建立hash索引，提高查询速度；两条相同的sql，会用到AHI；
			
		4、异步IO：异步IO操作、合并IO；
		
		5、刷新邻接页
			当刷新一个脏页时，InnoDB会检测该页所在区的所有页，如果是脏页，那么一起进行刷新。
			innodb_flush_neighbors;
			
第3章：文件
	参数文件、日志文件、socket文件、pid文件、mysql表结构文件、存储引擎文件；
	
	1、参数文件
		mysql--help|grep my.cnf
		select * from GLOBAL_VARIABLES where variable_name like 'innerdb_buffer%'\G;
		show variables like 'innodb_buffer%';
		
		mysql数据库中的参数可以分为两类：
			动态参数：可以在mysql实例运行中进行更改；
			静态参数；不能在mysql实例运行中进行更改；
			set @@global. | @@session. var_name = expr;
			
	2、日志文件：错误日志、慢查询日志、查询日志、二进制日志；
		错误日志：mysql的启动、运行、关闭过程进行了记录；
			show variables like 'log_error';
			system hostname: 查看主机名；
			
		慢查询日志：记录查询大于long_query_time的sql；
			show variables like 'long_query_time'; //默认情况下并不启动；
			show variables like 'log_throttle_queries_not_using_indexes'; //不使用索引的sql；
			
		查询日志：记录了所有对mysql请求的信息，主机名.log；
		
		二进制日志：记录了对mysql执行更改的所有操作，但不包含select和show操作，用以恢复、复制、审计；
			通过配置参数log-bin[=name]可以启动二进制日志，如果不指定name，则默认二进制日志文件名为主机名，
				后缀名为二进制日志的序列号，所在路径为数据库所在目录datadir：
				show variables like 'datadir';
				涉及的一些参数：max_binlog_size、binlog_cache_size、sync_binlog、binlog-do-db、binlog-ignore-db、log-slave-update、binlog_format;
			
			用途：恢复（recovery）、复制（replication）、审计（audit）
			
	3、套接字文件：在UNIX系统下本地连接mysql可以采用UNIX域套接字方式，show variables like 'socket';
	
	4、pid文件，记录进程的文件，路径由pid_file控制；
	
	5、表结构定义文件以fm为后缀的文件；
	
	6、存储引擎文件
		1、表空间文件
			innodb采用将存储的数据按表空间进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdata1的文件，该文件就是默认的表空间文件，
			用户可以通过参数innodb_data_file_path对其进行设置：innodb_data_file_path = /db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend
			这里将/db/ibdata1和/dr2/db/ibdata2两个文件用来组成表空间。若这两个文件位于不同的磁盘上，磁盘的负载可能被平均，因此可以提高数据库
			的整体性能；同时，两个文件的文件名都跟了属性，表示文件idbdata1的大小为2000MB，文件ibdata2的大小为2000M，如果用完了这2000M，该文件
			可以自动增长；
			设置innodb_data_file_path参数后，所有基于innodb存储引擎的表的数据都会记录到该共享表空间中。若设置了参数innodb_file_per_table，则
			用户可以将每个基于innodb存储引擎的表产生一个独立表空间，命名规则：表名.ibd，通过这样的方式，用户不用将所有数据都存放于默认的表空间中；
			
		2、重做日志文件
			默认情况下，在innodb的数据目录下会有两个名为ib_logfile0和ib_logfile1的文件，即重做日志文件，redo log file，宕机等情况下，用来保证数据的完整性；
			两个文件以循环写入的方式运行，log0写满后写log1，log1写满后写log0；
			
第4章：表
	1、在innodb中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表；
	
	2、所有数据都被逻辑地存放在一个空间中，称之为表空间，表空间由段(segment)、区(extent)、页(page，又称块)组成；
		
		表空间：默认为共享表空间，由段组成；
			InnoDB有一个默认的表空间，如果我们启用了参数innodb_file_per_table，则针对每张可以单独放在表空间里。这里需要注意的是，
			即时启用了innodb_file_per_table，也并不是表中所有的数据都单独放在自己的表空间里，单独表空间只存放数据、索引和插入缓冲，
			其它如Undo、系统事务信息、二次写缓冲等还是存放在默认共享表空间里。
		
		段：数据段、索引段、回滚段等；
		
		区：由64个连续的页组成，任何情况下每个区的大小都为1MB，innoDB引擎一次从磁盘上申请4-5个区；
		
		页：InnoDB磁盘管理的最小单位，每个页的大小为16KB，可以通过innodb_page_size设置为4KB、8KB、16KB；
		
		行：InnoDB表中数据按行存储；
		
	3、mysql约束：primary Key、Unique Key、Foreign Key、Default、NOT NULL；
		alter table table_name add unique key unique_name (column_name, ...);
		
	4、触发器、视图；
	
	5、分区表
		show variables like '%partition%';//查看当前数据库是否启用了分区功能；
		
		Range分区：行数据基于属于一个给定连续区间的列值被放入分区；根据num的取值范围分区；
		List分区：和range分区类似，只是list分区面向的是离散的值；根据姓氏范围进行分区；
		HASH分区：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数；取某个字段的hash值分区；
		KEY分区：和hash分区类似，不同之处在于hash分区使用用户定义的函数分区，而key分区根据mysql数据库提供的哈希函数来进行分区；
		COLUMN分区：前面4种分区条件是：分区列必须是整型，如果不是整型，需要转化为整型；如YEAR()、TO_DAYS()等；
			可视为Range分区和List分区的一种进化；
			column可以直接使用非整型的数据进行分区，如下：
				int、smallint、tinyint、bigint;
				date、datetime；
				char、varchar、binary、varbinary;
			
			
		不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分；
		
		查看分区信息
			select * from information_schema.PARTITIONS where table_schema = database() and table_name = 't_order';
		
		//range分区
		create table t_range(
			id int primary key
		)engine=inndb
		partition by range(id)(
			partition p0 values less than (10),
			partition p1 values less than (20)
		);
		
		create table t_list(
			a int,
			b int
		)engine=innodb
		partition by list(b)(
			partition p0 values in (1, 3, 5, 7, 9),
			partition p1 values in (2, 4, 6, 8)
		);
		
		create table t_hash(
			a int,
			b datetime
		)engine=innodb
		partition by hash (year(b))
		partitions 4;
		//通过mod模数分区；
		
		create table t_key(
			a int,
			b datetime
		)engine=innodb
		partition by key(b)
		partitions 4;
		//通过内部的哈希函数进行分区；
		
		create table t_column(
			a int,
			b datetime
		)engine=innodb
		partition by range columns(b)(
			partition p0 values less than ('2009-01-01'),
			partition p1 values less than ('2010-01-01')
		);
	
		create table t_column(
			first_name varchar(25),
			last_name varchar(25),
			street_1 varchar(30),
			street_2 varchar(30),
			city varchar(15),
			renewal date
		)engine=innodb
		partition by list columns(city)(
			partition p0 values in ('bj', 'sh', 'sz'),
			partition p1 values in ('newy', 'abc')
		);
		
		子分区：在分区的基础上再进行分区，允许在RANGE和LIST的分区上再进行分区；
		
		分区中的NULL值
			RANGE分区：插入less than的分区；如果不存在less than分区，插入NULL也没指定分区，将会报错；
			
			HASH、KEY分区，任何分区函数都会将含有NULL值的记录返回为0；

第5章：索引管理
	B+树：
		1、所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字是有序的；
		2、不可能在非叶子结点命中；
		3、非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；
		4、更适合文件索引系统，是一种平衡查找树；
		5、叶子节点双向链表；
		
	B+树索引可以分为聚集索引和辅助索引；
		InnoDB存储引擎表是索引组织表，即表中数据按照主键顺序存放，而聚集索引就是按照每张表的主键构造一棵B+树，
		同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页；聚集索引的这个特性决定了
		索引组织表中数据也是索引的一部分。
		
		数据页上存放的是完整的每行的记录，而在非数据页的索引页中，存放的仅仅是键值及指向数据页的偏移量，而不是一个完整的行记录；
		页按照主键的顺序进行排序，逻辑排序，非物理排序；
		
		对于辅助索引，叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签，
		该书签用来告诉InnoDB存储引擎哪里可以找到索引相对应的行数据；因为InnoDB存储引擎表示索引组织表，因此InnoDB存储引擎的
		辅助索引的书签就是相应行数据的聚集索引键；
		
		当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引
		来找到一个完整的行记录；举例来说，如果在一棵高度为3的辅助索引树中查找数据，那需要对这棵辅助索引树遍历3次找到指定主键，
		如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑
		IO访问以得到最终的一个数据页；
		
	聚簇索引：一般指主键唯一索引，索引直接指向数据块，通过索引可以直接查看数据；
	非聚簇索引/辅助索引：非唯一索引，指向数据块的地址，所以要查两次；
	
	B+索引在数据库中有一个特点是高扇出性，因此在数据库中，B+树的高度一般都在2-4层，这也就是说找某一键值的行记录时最多
		只需要2到4次IO，这倒不错；因为当前一般的机械磁盘每秒至少可以做100次IO，2-4次的IO意味着查询时间只需0.02-0.04秒；
	
	根据Leaf Page、Index Page的情况进行拆分、旋转、合并；
	
	数据库中的B+树索引可以分为聚集索引和辅助索引，但是不管是聚集索引还是辅助索引，其内部都是B+树的，即高度平衡的，叶子
		节点存放着所有的数据。聚集索引和辅助索引不同的是，叶子节点存放的是否是一整行的信息；
	
	创建索引、删除索引：
		alter table table_name add {index|key} [index_name] [index_type] (cloumn_name, ...) [index_option];
		
		alter table table_name drop {index|key} index_name;
		
		create [unique] index index_name [index_type] on table_name (column_name, ...);
		
		drop index index_name on table_name;
	
	查看索引
		show index from table_name;
		
	explain sql;
	
	Cardinality
		表示索引中不重复记录数目的预估值；
		analyze table table_name;
		
		更新Cardinality的策略：
			1、表中1/16的数据已发生过变化；
			2、stat_modified_counter>2000 000 000 //发生变化的次数；
	
	B+索引、联合索引、覆盖索引
	
第6章：锁，用于管理对共享资源的并发访问，提供数据的完整性和一致性；
	
	InnoDB提供一致性的非锁定读、行级锁支持；
	
	lock：处理事务对象，针对行、表等，主要保护数据库内容；事务对象、行表、数据库内容；
	latch：处理线程对象，针对临界资源，主要保护内存数据结构；线程对象、临界资源、内存数据结构；
	
	锁的类型
		共享锁/排他锁：行级锁：
			1、共享锁S：允许事务读一行数据；
			2、排他锁X：允许事务删除或更新一行数据；
		
		意向锁：表锁，表级别的锁；
			3、意向共享锁IS：事务想要或得一张表中某几行的共享锁；
			4、意向排他锁IX：事务想要获得一张表中某几行的排他锁；
		
		由于innoDB支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。
		
		X不兼容X、S、IX、IS；
		S兼容S、IS，不兼容X、IX；
		IS兼容S、IS、IX，不兼容X；
		IX兼容IS、IX，不兼容S、X；
		
		IX，IS是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X，S发生冲突
		
		事务先获取共享锁S，再获取排他锁X，需等待其他事务释放S、X才能获得X锁；
		如果需要对页上的记录进行上X锁，那么分别需要对数据库、表、页上意向锁IX，最后对记录上X锁；
		
		表INNODB_TRX、INNODB_LOCKS、INNODB_LOCK_WAITS可以监控锁的使用情况；
		
	一致性非锁定读
		指InnoDB存储引擎通过行多版本控制(MVCC)的方式来读取当前执行时间数据库中行的数据；
		如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放，而是会去读取行的一个快照；
			不同事务隔离级别下，读取的方式不同，并不是都采用非锁定一致性读，此外，非锁定一致性读，对于快照数据的
			定义也各不相同；
			
	一致性锁定读
		1、select ... for update; 对读取的记录加一个X锁；
		2、select ... lock in share mode; 对读取的记录加一个S锁；
	
	自增长与锁
		在innodb中，对每个含有自增长值的表都有一个自增长计数器；
		select max(auto_inc_col) from table_name for update; //获取计数器的值；
	
	外键和锁
		在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎自动对其加一个索引，因为这样
		可以避免表锁。对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT父表。但是对于父表的SELECT操作，不是
		使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这时使用的是SELECT...LOCK IN SHARE MODE方式，即
		主动对父表加一个S锁，如果这时父表上已经这样加X锁，子表上的操作会被阻塞。
	
	锁的3种算法
		1、Record Lock：单个行记录上的锁；
		2、Gap Lock：间隙锁，锁定一个范围，但不包含记录本身；
		3、Next-Key-Lock：Gap Lock + Record Lock，锁定一个范围，并且锁定记录本身，为了解决虚读/幻读的问题；
		事务是针对索引操作的，当对一个辅助索引上锁时，可能锁定的是一个范围的记录，在这个范围内插记录，会阻塞；
		
		oracle需要在serializable下才能防止虚读/幻读，但mysql在repeatable read下，通过Next-key-Lock解决了虚读/幻读问题；
		
		oracle默认隔离级别：read commited；mysql默认隔离级别：repeatable read；
		
	阻塞
		innodb_lock_wait_timeout用来控制阻塞等待的最大时间；
		innodb_rollback_on_timeout超时时是否要回滚；
		
	锁升级
		降低当前锁的粒度，如：把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁；
		
第7章：事务
	
	begin、commit、rollback、savepint、set transaction；
	
	事务的特性：ACID，原子性、一致性、隔离性、持久性；
	
	redo log：重做日志，保证事务的原子性、持久性；
	undo log：事务回滚及MVCC功能，保证事务的一致性；
	
	redo log：当提交事务commit时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的commit操作完成才算完成。
	
	undo log：存放在数据库内部一个特殊段中，称为undo段，undo段位于共享表空间内；
		在innodb中，MVCC的实现是通过undo log实现的；
		innodb_undo_directory用来设置rollback segment文件所在的路径。
		innodb_undo_logs用来设置rollback segment的个数，rollback segment的多少决定了在线事务的限制；
		innodb_undo_tablespaces用来设置构成rollback segment文件的数量，这样rollback segment可以较平均地分布在多个文件中；
		
		undo log是逻辑日志，一个delete对应一个insert，一个insert对应一个delete，一个update对应另外一个update；
	
	MVCC行多版本控制原理
		DATA_TRX_ID：6字节，标记了最新更新(insert/update/delete)这条行记录的transaction id，每处理一个事务，其值自动+1；
		DATA_ROLL_PTR：7字节，指向当前记录项的rollback segment的undo log记录，找之前版本的数据就是通过这个指针；
		DB_ROW_ID：6字节，当由innodb自动产生聚集索引时，聚集索引包括这个DB_ROW_ID的值，否则聚集索引中不包括这个值，这个用于索引当中；
		DELETE BIT：DELETE BIT位用于标识该记录是否被删除，这里的不是真正的删除数据，而是标志出来的删除。真正意义的删除是在commit的时候；
		
		InnoDB的MVCC，是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，一个保存了行的创建时间，一个保存行的删除时间，实际存储的
			不是时间，而是系统的版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和
			查询到的每行记录的版本号进行比较；
			
			SELECT
				Innodb检查每行数据，确保他们符合两个标准：
		　　    1、InnoDB只查找版本早于当前事务版本的数据行（也就是数据行的版本必须小于等于事务的版本），这确保当前事务读取的行，
					要么是在事务之前已经存在的，要么是事务自身插入或者修改过的；
		 　　   2、行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除；
				
		　　	符合了以上两点则返回查询结果。
				
		　　INSERT
		　　   InnoDB为每个新增行记录当前系统版本号作为创建ID。
				
		　　DELETE
		　   　InnoDB为每个删除行的记录当前系统版本号作为行的删除ID。
				
		　　UPDATE
				InnoDB复制了一行。这个新行的版本号使用了系统版本号。它也把系统版本号作为了删除行的版本。
		
第8章：复制
	MySQL的bin-log日志备份有三种模式，分别是：ROW、Statement、Mixed
	
	1、row：
		日志会记录成每一行数据被修改成的形式，然后再slave端再对相同的数据进行修改，只记录要修改的数据，只有value，不会有sql多表关联的情况。
		优点：在row模式下，bin-log中可以不记录执行的sql语句的上下文相关信息，仅仅需要记录哪一条记录被修改了，修改成什么信样了，
			所以row的日志内容会非常清楚的记录下每一行数据修改的细节，非常容易理解。而且不会出现在某些特定情况下的存储过程和function，
			以及trigger的调用和处罚无法被正确复制问题。
		缺点：在row模式下，所有执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。
	
	2、Statement
		每一条会修改数据的sql都会记录到master的binlog中，slave在复制的时候sql进程会解析成和原来master端相同的sql再执行。
		优点：在Statement模式下首先就是解决了row模式下的缺点，不需要记录记录每一行日志的变化，减少了bin-log日志量，节省了I/O以及存储资源，提高性能。
			因为它们只需要激励在master上所执行的语句的细节以及执行语句时候的上下文信息。
		缺点：在Statement模式下，由于它记录的执行语句，所以，为了让这些语句在slave端也能正确执行，那么它还必须记录每条语句在执行的时候的一些相关信息，
			也就是上下文信息，以保证所有语句在slave端被执行的时候能够得到和在master端执行时候的结果。另外，由于MySQL现在发展较快，很多的新功能不断的加入，
			使MySQL的复制遇到了不小的挑战，自然复制的时候涉及到越复杂的内容，bug也就越容易出现。在Statement中，目前已经发现不少情况会造成MySQL的复制出现问题，
			主要是修改数据的时候使用了某些特定的函数或者功能的时候会出现。
	
	3、Mixed
		从官方文档中看到，之前的MySQL一直都只有基于Statement的复制模式，知道5.1.5版本的MySQL才开始支持row模式。从5.0开始，
		MySQL的复制已经解决了大量老版本中出现的无法正确复制的问题。但是由于存储过程的出现，给MySQL replication又带来了更大的挑战。另外，看到官方文档说，
		从5.1.8版本开始，MySQL提供了除Statement和row之外的第三种模式：mixed，实际上就是前两种模式的结合。在mixed模式下，
		MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和row之间选择一种。新版本中的Statement还是和以前一样，
		仅仅记录执行的语句。而新版本的MySQL中对row模式也做了优化，并不是所有的修改都会以row模式来记录，比如遇到表结构变更的时候就会以Statement模式来记录，
		如果sql语句确实是update或者delete等修改数据的语句，那么还是会记录所有行的变更。
		update等操作用row，ddl用statement；
		
第9章：性能调优
	
	测试工具：sysbench、mysql-tpcc；
	
第10章：mysql调优参数
	/etc/my.cnf
	
	1、innodb_read_io_threads、innodb_write_io_threads来增大IO线程，对应CPU数；
	
	2、max_connections=200
		MySQL默认的最大连接数为100，MySQL服务器允许的最大连接数16384
		show status like '%thread%';
		比较threads_connected参数和前面提到的max_connections参数，也可以作为目前的系统负载的参照，决定是否需要修改连接数。
	
	3、innodb_buffer_pool_size
		缓冲池大小；
	
	4、innodb_undo_logs
		用来设置rollback segment的个数，rollback segment的多少决定了在线事务的限制；默认128；
		show engine innodb status;可以查看当前的事务个数；
	
	5、innodb_log_buffer_size=20M
		这是InnoDB存储引擎的事务日志所使用的缓冲区。类似于Binlog Buffer，InnoDB在写事务日志的时候，
		为了提高性能，也是先将信息写入Innofb Log Buffer中，当满足innodb_flush_log_trx_commit参数所设置的相应条件
		(或者日志缓冲区写满)之后，才会将日志写到文件 (或者同步到磁盘)中。可以通过innodb_log_buffer_size 参数
		设置其可以使用的最大内存空间。
	
	6、innodb_lock_wait_timeout用来控制阻塞等待的最大时间；
		innodb_rollback_on_timeout超时时是否要回滚；
	
	7、query_cache_size=40M
		要用来缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。
	
	8、back_log=500
		back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。
		也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，
		以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，
		将不被授予连接资源。将会报异常；
	
	9、wait_timeout=1800（单位为妙）
		我对wait-timeout这个参数的理解：MySQL客户端的数据库连接闲置最大时间值。
		说得比较通俗一点，就是当你的MySQL连接闲置超过一定时间后将会被强行关闭。
		MySQL默认的wait-timeout值为8个小时，可以通过命令show variables like 'wait_timeout'查看结果值;。
		设置这个值是非常有意义的，比如你的网站有大量的MySQL链接请求（每个MySQL连接都是要内存资源开销的 ），
		由于你的程序的原因有大量的连接请求空闲啥事也不干，白白占用内存资源，
		或者导致MySQL超过最大连接数从来无法新建连接导致“Too many connections”的错误。
		在设置之前你可以查看一下你的MYSQL的状态（可用show processlist)，如果经常发现MYSQL中有大量的Sleep进程，
		则需要 修改wait-timeout值了。
		
	10、innodb_additional_mem_pool_size=20M
		innodb_additional_mem_pool_size 设置了InnoDB存储引擎用来存放数据字典信息以及一些内部数
		据结构的内存空间大小，所以当我们一个MySQL Instance中的数据库对象非常多的时候，
		是需要适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率的。
	
	
	
	
	
	
	
	
	
	
	
	
	
	
